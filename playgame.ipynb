{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:32:19.403776Z",
     "start_time": "2021-06-02T22:32:19.358780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from game import controlled_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:32:21.558807Z",
     "start_time": "2021-06-02T22:32:19.405777Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from game import DO_NOTHING\n",
    "from game import JUMP\n",
    "\n",
    "games_count=0\n",
    "total_number_of_games =2\n",
    "\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from game import controlled_run\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(1,input_dim=1,activation='sigmoid'))\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# model.compile(Adam(lr=0.1),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# x_train = np.array([])\n",
    "# y_train = np.array([])\n",
    "\n",
    "\n",
    "# flaw in game design, it should be based on whether or not you make it past an opponent\n",
    "class Wrapper(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        controlled_run(self,0)\n",
    "        \n",
    "    def control(self,values):\n",
    "        global x_train\n",
    "        global y_train\n",
    "        \n",
    "        print(values)\n",
    "        \n",
    "        if(values['closest_enemy'] == -1):\n",
    "            return DO_NOTHING\n",
    "        \n",
    "        if(values['old_closest_enemy']!=-1):\n",
    "            print(values['closest_enemy'])\n",
    "            if(values['score_increased']==1):\n",
    "                x_train = np.append(x_train,[values['old_closest_enemy']/1000])\n",
    "                y_train = np.append(y_train,[values['action']])\n",
    "                \n",
    "        prediction=model.predict_classes(np.array([[values['closest_enemy']]])/1000)\n",
    "            \n",
    "        \n",
    "        return prediction\n",
    "    def reward(self,values):\n",
    "        print(\"No reward\")\n",
    "    def gameover(self,score):\n",
    "        global games_count\n",
    "        global x_train\n",
    "        global y_train\n",
    "        \n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        \n",
    "        if(games_count >0):\n",
    "            y_train_cat = to_categorical(y_train,num_classes=2)\n",
    "            model.fit(x_train,y_train_cat,epochs=50, verbose =1,shuffle=1)\n",
    "            \n",
    "        games_count+=1\n",
    "        \n",
    "        if games_count>total_number_of_games: \n",
    "            return\n",
    "        controlled_run(self,games_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:32:21.574807Z",
     "start_time": "2021-06-02T22:32:21.559776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# w=Wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:32:21.589777Z",
     "start_time": "2021-06-02T22:32:21.576778Z"
    }
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "EXPLORATION_MAX = .3\n",
    "EXPLORATION_MIN = 0.0\n",
    "EXPLORATION_DECAY = 0.995\n",
    "\n",
    "import numpy as np\n",
    "from game import DO_NOTHING\n",
    "from game import JUMP\n",
    "\n",
    "games_count=0\n",
    "total_number_of_games =50\n",
    "\n",
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(128, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(64, activation=\"relu\"))\n",
    "        self.model.add(Dense(32, activation=\"relu\"))\n",
    "        self.model.add(Dense(16, activation=\"relu\"))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        # self.memory.append((gamenumber,state,action,reward,next_state,done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "    # fit on past data\n",
    "    def experience_replay(self):\n",
    "        print(\"memory: \" + str(len(self.memory)))\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        # gamenumber = random(0,10)\n",
    "        # self.memory(gamenumber)\n",
    "        cul_reward = 0\n",
    "        index=0\n",
    "        lastmove = len(batch)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            q_update = reward\n",
    "            cul_reward+=reward\n",
    "            if not terminal:\n",
    "                \n",
    "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "            q_values = self.model.predict(state)\n",
    "            #print(np.argmax(q_values[0]))\n",
    "            #update the q value for that action \n",
    "            q_values[0][action] = q_update\n",
    "            #Fitting during experience replay?\n",
    "            self.model.fit(np.array(state), q_values, verbose=0)\n",
    "            index+=1\n",
    "        decay = cul_reward/500\n",
    "\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:32:21.621775Z",
     "start_time": "2021-06-02T22:32:21.591781Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# flaw in game design, it should be based on whether or not you make it past an opponent\n",
    "class Wrapper(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self,dqn_solver):\n",
    "        self.dqn_solver = dqn_solver\n",
    "        self.scores=[]\n",
    "        controlled_run(self,0)\n",
    "        \n",
    "    def control(self,values):\n",
    "        dqn_solver = self.dqn_solver\n",
    "        state = [[values['closest_enemy']/1000]]\n",
    "        step = 0 \n",
    "\n",
    "        self.old_state = state\n",
    "        action = dqn_solver.act(state)\n",
    "        self.action = action\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "        \n",
    "    def reward(self,values):\n",
    "        \n",
    "        dqn_solver = self.dqn_solver\n",
    "\n",
    "        state_next = values['closest_enemy']\n",
    "        reward= values['score_increased']\n",
    "        terminal=False\n",
    "        try:\n",
    "            self.state = state_next\n",
    "            dqn_solver.remember(self.old_state, self.action, reward, [state_next], terminal)\n",
    "            print(\"remembered\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def gameover(self,score):\n",
    "        global games_count\n",
    "        dqn_solver = self.dqn_solver\n",
    "        reward = -1\n",
    "        dqn_solver.remember(self.old_state, self.action, reward, self.state, True)\n",
    "        try:\n",
    "            print(\"Run: \" + str(games_count) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(score))\n",
    "        except:\n",
    "            print(\"Run: \" + str(games_count) + \", score: \" + str(score))\n",
    "\n",
    "        if(games_count >0):\n",
    "            print(\"replaying...\")\n",
    "            dqn_solver.experience_replay()\n",
    "\n",
    "        games_count+=1\n",
    "        self.scores.append(score)\n",
    "        if games_count>total_number_of_games: \n",
    "            return\n",
    "        controlled_run(self,games_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:37:22.016168Z",
     "start_time": "2021-06-02T22:32:21.624781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 0, exploration: 0.3, score: 6\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 1, exploration: 0.3, score: 5\n",
      "replaying...\n",
      "memory: 16\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 2, exploration: 0.3, score: 4\n",
      "replaying...\n",
      "memory: 22\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 3, exploration: 0.2985, score: 1\n",
      "replaying...\n",
      "memory: 34\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 4, exploration: 0.2970075, score: 4\n",
      "replaying...\n",
      "memory: 47\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 5, exploration: 0.29552246249999997, score: 1\n",
      "replaying...\n",
      "memory: 54\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 6, exploration: 0.2940448501875, score: 1\n",
      "replaying...\n",
      "memory: 61\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 7, exploration: 0.29257462593656247, score: 9\n",
      "replaying...\n",
      "memory: 86\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 8, exploration: 0.2911117528068797, score: 7\n",
      "replaying...\n",
      "memory: 96\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 9, exploration: 0.28965619404284526, score: 7\n",
      "replaying...\n",
      "memory: 106\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 10, exploration: 0.28820791307263105, score: 13\n",
      "replaying...\n",
      "memory: 123\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 11, exploration: 0.28676687350726787, score: 4\n",
      "replaying...\n",
      "memory: 131\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 12, exploration: 0.2853330391397315, score: 7\n",
      "replaying...\n",
      "memory: 140\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 13, exploration: 0.28390637394403284, score: 8\n",
      "replaying...\n",
      "memory: 150\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 14, exploration: 0.2824868420743127, score: 5\n",
      "replaying...\n",
      "memory: 159\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 15, exploration: 0.2810744078639411, score: 4\n",
      "replaying...\n",
      "memory: 166\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 16, exploration: 0.2796690358246214, score: 8\n",
      "replaying...\n",
      "memory: 175\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 17, exploration: 0.27827069064549825, score: 8\n",
      "replaying...\n",
      "memory: 187\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 18, exploration: 0.27687933719227076, score: 9\n",
      "replaying...\n",
      "memory: 196\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 19, exploration: 0.2754949405063094, score: 5\n",
      "replaying...\n",
      "memory: 203\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 20, exploration: 0.2741174658037779, score: 13\n",
      "replaying...\n",
      "memory: 218\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 21, exploration: 0.272746878474759, score: 2\n",
      "replaying...\n",
      "memory: 223\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 22, exploration: 0.2713831440823852, score: 17\n",
      "replaying...\n",
      "memory: 243\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 23, exploration: 0.27002622836197326, score: 13\n",
      "replaying...\n",
      "memory: 259\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 24, exploration: 0.2686760972201634, score: 11\n",
      "replaying...\n",
      "memory: 272\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 25, exploration: 0.26733271673406256, score: 7\n",
      "replaying...\n",
      "memory: 281\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 26, exploration: 0.26599605315039226, score: 10\n",
      "replaying...\n",
      "memory: 307\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 27, exploration: 0.2646660728846403, score: 1\n",
      "replaying...\n",
      "memory: 313\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 28, exploration: 0.26334274252021705, score: 1\n",
      "replaying...\n",
      "memory: 320\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 29, exploration: 0.26202602880761594, score: 0\n",
      "replaying...\n",
      "memory: 325\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 30, exploration: 0.26071589866357786, score: 2\n",
      "replaying...\n",
      "memory: 334\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 31, exploration: 0.25941231917026, score: 2\n",
      "replaying...\n",
      "memory: 340\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 32, exploration: 0.2581152575744087, score: 0\n",
      "replaying...\n",
      "memory: 345\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 33, exploration: 0.2568246812865366, score: 4\n",
      "replaying...\n",
      "memory: 357\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 34, exploration: 0.25554055788010394, score: 0\n",
      "replaying...\n",
      "memory: 363\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 35, exploration: 0.2542628550907034, score: 2\n",
      "replaying...\n",
      "memory: 371\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 36, exploration: 0.2529915408152499, score: 1\n",
      "replaying...\n",
      "memory: 377\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 37, exploration: 0.25172658311117363, score: 2\n",
      "replaying...\n",
      "memory: 386\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 38, exploration: 0.25046795019561774, score: 1\n",
      "replaying...\n",
      "memory: 391\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 39, exploration: 0.24921561044463966, score: 4\n",
      "replaying...\n",
      "memory: 406\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 40, exploration: 0.24796953239241645, score: 1\n",
      "replaying...\n",
      "memory: 416\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 41, exploration: 0.24672968473045437, score: 2\n",
      "replaying...\n",
      "memory: 427\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 42, exploration: 0.24549603630680208, score: 5\n",
      "replaying...\n",
      "memory: 437\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 43, exploration: 0.24426855612526807, score: 3\n",
      "replaying...\n",
      "memory: 448\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 44, exploration: 0.24304721334464174, score: 1\n",
      "replaying...\n",
      "memory: 460\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 45, exploration: 0.24183197727791853, score: 0\n",
      "replaying...\n",
      "memory: 465\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 46, exploration: 0.24062281739152894, score: 1\n",
      "replaying...\n",
      "memory: 471\n",
      "remembered\n",
      "remembered\n",
      "remembered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 47, exploration: 0.2394197033045713, score: 6\n",
      "replaying...\n",
      "memory: 489\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 48, exploration: 0.23822260478804844, score: 2\n",
      "replaying...\n",
      "memory: 497\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 49, exploration: 0.2370314917641082, score: 6\n",
      "replaying...\n",
      "memory: 518\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "remembered\n",
      "Run: 50, exploration: 0.23584633430528767, score: 3\n",
      "replaying...\n",
      "memory: 530\n"
     ]
    }
   ],
   "source": [
    "dqn_solver = DQNSolver(1,2)\n",
    "game = Wrapper(dqn_solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:49:46.525899Z",
     "start_time": "2021-06-02T22:49:46.515899Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddqn_solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7db291b5407d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mddqn_solver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ddqn_solver' is not defined"
     ]
    }
   ],
   "source": [
    "dqn_solver.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:37:22.340166Z",
     "start_time": "2021-06-02T22:32:19.178Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "alpha = 0.5\n",
    "learning_rate_adam = 0.01\n",
    "epsilon = 0.999\n",
    "epsilon_decay = 0.99\n",
    "class DQN:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        \n",
    "        self.memory = []\n",
    "        self.batch_size = 20\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(64, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(32, activation=\"relu\"))\n",
    "        self.model.add(Dense(16, activation=\"relu\"))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=learning_rate_adam))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "        q = self.model.predict(state)\n",
    "        return np.argmax(q[0])\n",
    "\n",
    "    def experience_replay(self):\n",
    "        print(self.memory,self.batch_size)\n",
    "        mem_sample = random.sample(self.memory, min(len(self.memory),self.batch_size))\n",
    "        for state, action, reward, next_state, done in mem_sample:\n",
    "            update_value = reward\n",
    "            if not done:\n",
    "                update_value = self.alpha * (reward + self.gamma * np.max(self.model.predict(next_state)[0]))\n",
    "            q = self.model.predict(state)\n",
    "            q[0][action] = update_value\n",
    "            # print(state,type(state))\n",
    "            # print(q,type(q))\n",
    "            self.model.fit(np.array(state), q, verbose=0)\n",
    "        self.epsilon *= epsilon_decay\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T22:37:22.342168Z",
     "start_time": "2021-06-02T22:32:19.179Z"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# dqn_solver = DQN(1,2)\n",
    "# game = Wrapper(dqn_solver)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
